# GANS-implementation
Implementation of GAN's from scratch on MNIST dataset

GAN is a combination of a generator and a discriminator
The generator generates images from standard normal distribution or to be precise noise.
This process is works exactly opposite to the process of feature embedding as used in other DNN workflow.
We generate images from latent space variation

The discriminator is inturn trained on both the fake images generated by the generator and the real images from the MNIST dataset.
Thus we try to analyse the loss functions i.e binary cross entropy in this case.

As can be seen from the colab notebook the digits becomes readable by human eye and seems close to reality.

Also as the noise is generated from the standard normal distribution we use "tanh" activation function in the end.
To scale the i/p's for better training we scale them between -1 to +1
